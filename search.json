[{"path":"https://eduaguilera.github.io/WHEP/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 WHEP authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":[]},{"path":"https://eduaguilera.github.io/WHEP/articles/workflow-intro.html","id":"cloning-the-repository","dir":"Articles","previous_headings":"Git intro","what":"Cloning the repository","title":"Follow the workflow","text":"get started Git, need operating system recognize Git commands. assume Windows, install Git . know whether 32 64 bits version, likely need 64 bit one. now something called ‘Git Bash’ installed, like command line tool (similar Windows CMD). can open Git Bash inside specific directory (just technical name folders use now ) right-clicking desired directory file explorer selecting ‘Open Git Bash ’. However, recommend learn basic commands navigate command line (now , writing <-text> part command, just use placeholder need write ): Print current directory: just useful can see right now. List files current directory: Suppose know exact path follow know inside certain subdirectory one right now. Listing everything current directory ls useful way spot subdirectory looking , can navigate inside cd. Move another directory relative one right now: can use ls cd <relative-path> repeatedly directory want place subdirectory containing repository. , can double check using pwd. assume repository want contribute already exists. can go page Github copy URL seen image :  git terminology used ‘downloading’ repository local file system ‘cloning’. can clone remote repository (case Github) using following command: called cloning via HTTPS. browser open ask introduce Github credentials. ways cloning like SSH, scope guide.","code":"pwd ls cd <relative-path-where-to-move> git clone <url-you-copied>"},{"path":"https://eduaguilera.github.io/WHEP/articles/workflow-intro.html","id":"pulling-remote-changes","dir":"Articles","previous_headings":"Git intro","what":"Pulling remote changes","title":"Follow the workflow","text":"Now new directory created content repository local file system. now see basic git commands need daily usage. assume inside repository. explain example. Suppose want start contributing repository. good practice (one enforce use) make code changes ‘different place’ ones currently see repository. things see now called ‘main branch’, make code changes ‘new branch’, start content main one, evolve different changes. done anything yet, main branch (maybe called ‘main’ ‘master’, just conventions, assume called ‘main’). can use command git status check (mind terminal looks different screenshots, can use commands Git Bash):  local version repository need match remote version (one store Github case), start work new branch, keep main branch date case someone added new code Github repository since last time checked. get new remote changes local repository using command  case already remote changes, message says ‘Already date’, message different missing changes. ‘easy way’ . command git pull tries fetch changes equivalent remote branch, .e., one name remote local repository. may always work expected way always specify remote branch want get changes (highly recommend always using explicitly): example, imagine asked someone help branch added new changes branch, locally. , branch called -branch, already branch locally, want use command Likewise, first example shown (keeping main branch updated), always explicit:","code":"git pull git pull origin <name-of-remote-branch> git pull origin my-branch git pull origin main"},{"path":"https://eduaguilera.github.io/WHEP/articles/workflow-intro.html","id":"creating-our-own-branch","dir":"Articles","previous_headings":"Git intro","what":"Creating our own branch","title":"Follow the workflow","text":"pull, now safely date remote changes. Now time learn create ‘branch’, start working new code. use following command:  command git checkout <name--branch> used change one branch another (now see files changes branch). Additionally, add -b option, create branch given name already exist, case example. branch name something like author/name--branch. Thus, common practices naming branches (follow) : contain caps (lowercase) Words separated dashes (-) name includes author descriptive name separated slash (/) descriptive name ideally start action (verb) imperative style (fix, create, test…). Ermenegildo wants create code preprocessing bilateral trade data, acceptable branch name ermenegildo/preprocess-bilateral-trade-data.","code":"git checkout -b <name-of-branch>"},{"path":"https://eduaguilera.github.io/WHEP/articles/workflow-intro.html","id":"adding-changes-to-our-branch","dir":"Articles","previous_headings":"Git intro","what":"Adding changes to our branch","title":"Follow the workflow","text":"Now branch can start working changes. work , keep track changes git. can add changes using command dot means ‘directory’, essentially adds new changes, .e. things inside directory. can add just specific file instead using command  adding changes, must ‘commit’ . commit step actually saves changes git history. command common practice commit messages start verb infinitive (imperative style), indicating action performed, e.g., 'Create tests bilateral trade data preprocessing'.  common practice make small commits, , include just changes commit, easier keep track work’s history, instead just single commit done everything. Ultimately, amount commits decision, just one commit per branch.","code":"git add . git add <relative-name-of-file> git commit -m 'Some descriptive message for your changes'"},{"path":"https://eduaguilera.github.io/WHEP/articles/workflow-intro.html","id":"pushing-our-changes","dir":"Articles","previous_headings":"Git intro","what":"Pushing our changes","title":"Follow the workflow","text":"committing, now changes local git history, probably also add remote Github repository. using command Now able see changes branch Github , just need select branch instead main one. remember push changes regularly remote repository. Otherwise risk bunch code features local computer lost something happened . aligned previous suggestion creating many smaller commits opposed giant ones, can also push frequently.","code":"git push origin <name-of-branch>"},{"path":"https://eduaguilera.github.io/WHEP/articles/workflow-intro.html","id":"creating-a-pull-request","dir":"Articles","previous_headings":"Git intro","what":"Creating a pull request","title":"Follow the workflow","text":"Suppose done changes want add main branch. Mixing one branch another known ‘merging’. case like merge new branch main branch. can done forcefully, common practice following create known ‘Pull request’ branch main one, directly Github, pushed changes.   can see changes made (differ main branch) clicking ‘Create pull request’. see following, add title description explain done. finally click ‘Create pull request’ .  Now Pull Request (often abbreviated PR) created next step ask someone’s review.  Ideally changes merged someone else reviews code. person might find things change request changes merging, keep working branch satisfied. accept changes ready merge branch main one, process done. However, sometimes additional step must passed merging, related automatic code checks, e.g. check whether code well formatted whether passes tests successfully. configured, can run automatically creating Pull Request. indeed work , explain automatic checks better Automatic checks Pull Requests section. working branch, others may merged branches main branch branch outdated. creating Pull Request , make sure branch also date everything already main branch. Recall pulling remote changes section can command Even locally branch directly try fetch changes different remote one (case main), works expected, , tries merge new changes main branch local one. automatic merge works times, sometimes may find conflicts, program know combine everything neatly. happens, must manually check parts code kept. next section explain solve conflicts.","code":"git pull origin main"},{"path":"https://eduaguilera.github.io/WHEP/articles/workflow-intro.html","id":"solving-conflicts","dir":"Articles","previous_headings":"Git intro","what":"Solving conflicts","title":"Follow the workflow","text":"noted previous section, sometimes git pull another branch remote one (missing changes), can find conflicts. conflict looks like : conflict, least three lines added git separate conflicting parts. conflict starts line <<<<<<< HEAD, get ======= line, lines content added. one end >>>>>>> some_branch_name, lines content someone else added yet. solving conflict essentially means removing three lines added git. three options . decide one want depending situation: Keep content. Solving conflict involve removing lines except: Keep content. remove everything except: Keep () content parts, even adapt adding things. remove three lines added git everything else want keep, leaving something like mix: find conflicts (advise manually), use text finding tool editor, look text HEAD, always appears first line conflict. solved conflicts, rest steps explained previous sections, involving git add git commit, pull also counts code change, make commit . case wondering, perform pull without conflicts, creating commit git , automatically. whether solved conflicts git , always commit representing .","code":"<<<<<<< HEAD this is my content that I just added ======= this is some different conflicting content from the branch I pulled from >>>>>>> some_branch_name this is my content that I just added this is some different conflicting content from the branch I pulled from this is my content that I just added this is some different conflicting content"},{"path":[]},{"path":"https://eduaguilera.github.io/WHEP/articles/workflow-intro.html","id":"project-structure","dir":"Articles","previous_headings":"R package and renv intro","what":"Project structure","title":"Follow the workflow","text":"seems clear even though work fine bare R scripts run directly, working large project makes sense kind file structure, keep everything organised. can build ad-hoc file structures, probably come something rather simple. , instead, focus using standard structure R package. standard everyone follow want projects turn packages can publicly downloaded anyone CRAN repositories. Just way , e.g., install.packages(tidyverse) install Tidyverse packages, follow standard R package structure, can upload package one install.packages(your_package) way. Even want upload package, still advantages follow structure. one follow, rest section try explain different parts, become part workflow. whole structure R package:  Luckily, lot files need know , least now, try explain important ones next sections. whole R packages book followed setup basics project. well written available free online, interested knowing R packages project structure, recommend checking book.","code":""},{"path":"https://eduaguilera.github.io/WHEP/articles/workflow-intro.html","id":"virtual-environments-with-renv","dir":"Articles","previous_headings":"R package and renv intro","what":"Virtual environments with renv","title":"Follow the workflow","text":"just mentioned going use R package structure, seems R package developers use renv… ? least seem include renv related files package repositories… Well, use ? writing guide bit confused mixing things, conclusion just hurt way, renv just makes things easier without apparent drawbacks (tell know ). creating packages, want make sure work fresh installations, .e., computers anything unnecessary installed. package creation process use , need know anything renv, fine. packages use file called DESCRIPTION includes information packages needs dependencies, see later . can just try benefit using virtual environments. OK, virtual environments? fancy term, practical meaning quite simple. First consider following: using , means just global R installation computer, whenever install package, installed globally. want run someone’s code use bunch packages usually , install able run code, mix packages. want uninstall , lot manual work make sure know (package dependencies also installed, sure used packages also package already ). want write code uses packages, want another person run , make list packages used project, install packages projects necessary . even make ‘package list’, person go whole code run install new package every time code fails missing one. Overall, poor experience. Virtual environments try fix . Essentially, provide ‘local’ installation packages, visible inside project, get mixed global R installation individual projects. practice, virtual environment just folder containing installed packages, isolated folder contains global R installation. like several different R installations, one packages versions. Chances follow guide existing repository already using renv (can skip renv::init() step). case, open R prompt root directory project run inside prompt: probably ask close reopen clean prompt. , every time open R prompt inside project, automatically use renv work within virtual environment. use renv first time project already uses , open R prompt root directory, renv package installed automatically. Now renv, can, example, install testing package install.packages(\"testthat\") global installation, means work inside project. way isolating project dependencies making projects reproducible, letting others know exactly packages code needs run, add unnecessary ones may projects, mentioned previously. ‘list’ required packages project, along versions, used renv manage virtual environment, file called renv.lock. installing new packages, file updated automatically manually running update renv.lock file packages renv finds used code. reason need install package explicitly used code, may fail recognize . case, instead explicitly call renv::snapshot(type=\"\") force every package renv environment added renv.lock. push file repository. someone else wants reproduce code, may run install packages renv.lock may still installed, , project level, conflicting global R installation. use Github others, might also need every time pull remote changes someone else included new package, date . case, opening R shell, probably remind missing packages virtual environment message:  basically need start using virtual environment, keeping mind commands renv::snapshot(): add new required packages renv.lock file renv::restore(): install packages renv.lock yet wrote introduction renv reading package documentation. want learn , can read package website. directly related renv usage, wanted highlight Windows may errors trying install R packages. times may related missing operating system dependencies commands. Windows easily fixable installing version Rtools matches R version. selecting version can download clicking first installer link. installing Rtools, can try install R packages wanted.","code":"renv::init() renv::snapshot() renv::restore()"},{"path":"https://eduaguilera.github.io/WHEP/articles/workflow-intro.html","id":"writing-code","dir":"Articles","previous_headings":"R package and renv intro","what":"Writing code","title":"Follow the workflow","text":"Looking back package’s file structure, R/ directory put main code. R files stored must contain top-level code, , must inside functions. can add one function file somehow related, must many either. file becomes large several functions inside, consider splitting shorter files. Take following code example, written colleague Justin (understand code, can keep reading). save R/sources.R. sample code things keep mind: code written inside functions, three . name two starts dot. convention private functions. Private functions just helpers used functions file, need used outside. functions private, called public, ones want ‘export’, sense want allow used outside file. sources.R example, first function public. public function large commented section , line starting #'. special type comment considered documentation. Every public function must documented way (special function documentation next section). private functions can introduced explanatory comments consider necessary, normal comments instead (starting just #, without single quote). important take anyway files contain code inside functions nothing outside .","code":"#' Create a new dataframe where each row has a year range into one where each #' row is a single year, effectively 'expanding' the whole year range #' #' @param trade_sources A tibble dataframe #' where each row contains the year range #' #' @returns A tibble dataframe where each row #' corresponds to a single year for a given source #' #' @export #' #' @examples #' trade_sources <- tibble::tibble( #'   Name = c(\"a\", \"b\", \"c\"), #'   Trade = c(\"t1\", \"t2\", \"t3\"), #'   Info_Format = c(\"year\", \"partial_series\", \"year\"), #'   Timeline_Start = c(1, 1, 2), #'   Timeline_End = c(3, 4, 5), #'   Timeline_Freq = c(1, 1, 2), #'   `Imp/Exp` = \"Imp\", #'   SACO_link = NA, #' ) #' expand_trade_sources(trade_sources) expand_trade_sources <- function(trade_sources) {   non_na_cols <- c(\"Trade\", \"Timeline_Start\", \"Timeline_End\", \"Timeline_Freq\")   trade_sources |>     dplyr::filter(!.any_na_col(non_na_cols)) |>     .expand_trade_years() |>     dplyr::mutate(       Name = dplyr::if_else(         Info_Format == \"year\", paste(Name, Year, sep = \"_\"), Name       ),       ImpExp = `Imp/Exp`,       In_Saco = as.integer(!is.na(SACO_link)),     ) }  .expand_trade_years <- function(trade_sources) {   trade_sources <- dplyr::mutate(trade_sources, No = dplyr::row_number())    trade_sources |>     dplyr::group_by(No) |>     tidyr::expand(Year = seq(Timeline_Start, Timeline_End, Timeline_Freq)) |>     dplyr::inner_join(trade_sources, by = \"No\") }  .any_na_col <- function(cols_to_check) {   dplyr::if_any(dplyr::all_of(cols_to_check), is.na) }"},{"path":"https://eduaguilera.github.io/WHEP/articles/workflow-intro.html","id":"function-documentation","dir":"Articles","previous_headings":"R package and renv intro","what":"Function documentation","title":"Follow the workflow","text":"special commented section seen previous example used package called roxygen2. follow exact syntax, package can automatically build really neat documentation package us. Let’s try understand basic structure. reference, different parts: small description function, nothing else. small description parameter function receives. like: see think OK add linebreaks , long parameter starts @param. small description value function returns. start @returns. simple line containing @export indicate function can used package, .e., public. ‘code’ section examples illustrate function’s behaviour. must start @examples, can write usual R code. processed, automatically runs code adds lines output documentation. options enough get us started nice documentation. Writing articles section learn generate see documentation. example, look something like (note autogenerated example code output):","code":"#' Create a new dataframe where each row has a year range into one where each #' row is a single year, effectively 'expanding' the whole year range #' @param param_name_1 Description of param 1 #' @param param_name_2 Description of param 2 #' ... #' @param trade_sources A tibble dataframe #' where each row contains the year range #' @returns A tibble dataframe where each row #' corresponds to a single year for a given source #' @export #' @examples #' trade_sources <- tibble::tibble( #'   Name = c(\"a\", \"b\", \"c\"), #'   Trade = c(\"t1\", \"t2\", \"t3\"), #'   Info_Format = c(\"year\", \"partial_series\", \"year\"), #'   Timeline_Start = c(1, 1, 2), #'   Timeline_End = c(3, 4, 5), #'   Timeline_Freq = c(1, 1, 2), #'   `Imp/Exp` = \"Imp\", #'   SACO_link = NA, #' ) #' expand_trade_sources(trade_sources)"},{"path":"https://eduaguilera.github.io/WHEP/articles/workflow-intro.html","id":"writing-tests","dir":"Articles","previous_headings":"R package and renv intro","what":"Writing tests","title":"Follow the workflow","text":"just wrote function, done , now move another function… . probably thought check somehow function indeed correct expect. Right now easy just load function R prompt try examples , next month someone make change code? manual testing make sure break functionality. need change dozens functions? many time spend testing ? think can understand really time consuming better way. Tests can automatized. can write tests whenever create new function, together prove function expect, later add changes function, already test can run automatically see function still correct. course, completely accurate. Maybe changed function, functionality also changed, test accurate anymore tweaked well, represent really want. still much less work always testing function manually R prompt, eventually just get used . package used write tests well integrated R package creation workflow testthat. using write automated tests. , looking structure R package, tests go (surprise!) directory tests/. directory file called testthat.R setups testthat changed, actual tests write go tests/testthat/ subdirectory. convention name test files way R files test- prefix. case, example, R file R/sources.R, test file tests/testthat/test-sources.R. Let’s see one tests look like: , understand whole code. Just note use two functions testthat package: testthat::test_that: main function used delimit test . receives text description test checking, body containing code test . testthat::expect_equal: just one many utilities testthat brings actually assert things test’s code. probably general assert, just checks everything identical arguments, including internal object metadata, just “appearance” (may see printing object). can look testing utility functions documentation. now test. execute ? recommended run test usual R code (e.g. run file script). Instead, functions provided testthat running tests. : testthat::auto_test_package(): one run tests package first time, stop running, wait code changes. means whenever ‘save’ test file, reruns tests file. extremely useful actively writing tests, can get fast feedback. testthat::test_file(): one receives argument path test file, runs tests inside . example, run case testthat::test_file(\"tests/testthat/test-sources.R\"). testthat::test_dir(): case, different running tests e.g. subdirectories tests/testthat one. subdirectory tests/testthat/sources many test files related sources, run testthat::test_dir(\"tests/testthat/sources\") test files inside directory executed. testthat::test_package(): general one. just runs tests project. can useful run tests actively working . suppossed make tests pass, see next section, checks package must pass valid (can publicly uploaded), tests definitely one .","code":"library(\"testthat\")  test_that(\"trade source data is expanded from year range to single year rows\", {   trade_sources <- tibble::tibble(     Name = c(\"a\", \"b\", \"c\", \"d\", \"e\"),     Trade = c(\"t1\", \"t2\", \"t3\", NA, \"t5\"),     Info_Format = c(\"year\", \"partial_series\", \"year\", \"year\", \"year\"),     Timeline_Start = c(1, 1, 2, 1, 3),     Timeline_End = c(3, 4, 5, 1, 2),     Timeline_Freq = c(1, 1, 2, 1, NA),     `Imp/Exp` = \"Imp\",     SACO_link = NA,   )   expected <- tibble::tibble(     Name = c(\"a_1\", \"a_2\", \"a_3\", \"b\", \"b\", \"b\", \"b\", \"c_2\", \"c_4\"),     Trade = c(\"t1\", \"t1\", \"t1\", \"t2\", \"t2\", \"t2\", \"t2\", \"t3\", \"t3\"),     Info_Format = c(       \"year\", \"year\", \"year\", \"partial_series\", \"partial_series\",       \"partial_series\", \"partial_series\", \"year\", \"year\"     ),     Year = c(1, 2, 3, 1, 2, 3, 4, 2, 4),   )    actual <-     trade_sources |>     expand_trade_sources() |>     dplyr::ungroup()    expect_equal(     dplyr::select(actual, Name, Trade, Info_Format, Year),     expected   ) })"},{"path":"https://eduaguilera.github.io/WHEP/articles/workflow-intro.html","id":"r-cmd-check","dir":"Articles","previous_headings":"R package and renv intro","what":"R CMD Check","title":"Follow the workflow","text":"standard tool contains several steps (‘checks’) every project wants package uploaded CRAN repositories must pass. part code workflow, also responsible make check pass, also see Automatic checks Pull Requests section. check known ‘R CMD check’, actually easy run: whole output call rather long, since lists different checks makes, end, issues, output see:  OK, just followed steps guide included example code Writing code Writing tests sections, check ended successfully 0 errors, probably see (among really large output), error like :  problem performing check package, must build . , must know packages dependencies. , just followed everything , never got , built package just include packages. fix , must quick look DESCRIPTION file. file, Imports section make sure dependencies code saved specifically R/ directory. hand, dependencies code written places, tests/ vignettes/ (see one following Writing articles section), included Suggests section DESCRIPTION file. Together two fields tell everyone dependencies package needs work correctly. adding , run devtools::check() confirm fail anymore (least errors). go detail checks performed. slowly learn whenever show real issues code running check tool. Just keep mind one important points tests write also executed , ‘R CMD check’ also fails one tests fail. really want know checks, can read, e.g., detailed list.","code":"devtools::check() Package: WHEP Title: What the Package Does (One Line, Title Case) Version: 0.0.0.9000 Authors@R:     person(\"First\", \"Last\", , \"first.last@example.com\", role = c(\"aut\", \"cre\")) Description: What the package does (one paragraph). License: MIT + file LICENSE Imports:     dplyr,     tidyr Encoding: UTF-8 Roxygen: list(markdown = TRUE) RoxygenNote: 7.3.2 Suggests:     knitr,     rmarkdown,     testthat (>= 3.0.0),     tibble,     ggplot2,     here,     googlesheets4 Config/testthat/edition: 3 VignetteBuilder: knitr URL: https://eduaguilera.github.io/WHEP/"},{"path":"https://eduaguilera.github.io/WHEP/articles/workflow-intro.html","id":"writing-articles","dir":"Articles","previous_headings":"R package and renv intro","what":"Writing articles","title":"Follow the workflow","text":"ever got check popular R package website (e.g. dplyr), may know section called Articles top, open one , see indeed looks like article, mixing natural text code rendering. ideal want make guides package, kind reports general. can probably guess, guide reading built way. Luckily already well integrated R packages workflow, learn make articles easily. Everything want appear Articles section site, included vignettes/ directory package. inside directory, file ends .Rmd extension considered one article. extension name stands ‘R Markdown’, mix R code Markdown text. know Markdown can start , e.g., intro. Following previous example, can create file called trade-sources-coverage.Rmd following code 1 (, thanks Justin): first part code, namely following metadata always present (just change article’s title). see just Markdown, can write R code chunks inside triple backticks, difference code executed, default also able see output rendered article. next chunk (\"r setup\" option) used initialization code may need throughout rest article. time writing really know implications writing \"r setup\" option writing code normal R code chunk (without option), least good practice. Note package loaded package (called WHEP case). rest code provided just usual Markdown text intertwined usual R code chunks. special case code chunks plots, get see actual plot rendered article, fig.alt option necessary order get R CMD check warning, used text explains rendered image people using screen readers case displayed correctly browser. Now R Markdown article, like visualize . least two useful R commands . first one creates whole documentation website locally computers, automatically opens browser site. simply: now able see article ‘Articles’ section. look something like one can see directly site Trades sources coverage (additional plots). running command , need rerun every time want see changes, since takes bit longer run. can instead use simpler one checks code changes articles reruns changed. completely convinced equivalent, since seems point one failed one worked , something strange (like building guide writing R Markdown inside R Markdown) probably work . pkgdown::build_articles() one still fail error indicating package loaded. likely refers package. Since use code package inside R markdown, package must also installed. running pkgdown::build_site(), think package installed temporary directory execution, maybe work anymore calling pkgdown::build_articles() . case, may want try installing package first via devtools::install(). Note assumes change package code (one R/ directory) actively working articles. , reinstall package every time change something R/ directory. mentioned previous section, also remember include package dependencies article code uses Suggests part DESCRIPTION file, get errors packages found building articles running R CMD check. way can render articles default HTML, browsers use. site perfect can keep date, case need , also able export article PDF. work, first need LaTeX distribution installed. Windows, can try MiKTeX (maybe start ). Remember choose “Yes” asked “missing packages installation fly”, otherwise PDF generation R might fail. LaTeX distribution installed, can build PDF article just single command: output PDF (probably expected) look exactly like one site, style (LaTeX’s style). also valid formats, can look curious, thought PDF output format useful one besides HTML website generation.","code":"--- title: \"Trade sources year coverage\" output: rmarkdown::html_vignette vignette: >   %\\VignetteIndexEntry{Trade sources year coverage}   %\\VignetteEngine{knitr::rmarkdown}   %\\VignetteEncoding{UTF-8} ---  ```_{r, include = FALSE} knitr::opts_chunk$set(   collapse = TRUE,   comment = \"#>\" ) ```  ```_{r setup} library(WHEP) key_path <- here::here(Sys.getenv(\"GOOGLESHEETS_AUTH_FILE\")) googlesheets4::gs4_auth(path = key_path) ```  First we read the trade sources sheet and build a dataframe where each row accounts for one year. ```_{r} # Step 1: Authentication sheet_url <- \"1UdwgS87x5OsLjNuKaY3JA01GoI5nwsenz62JXCeq0GQ\"  # PART 1: trade_sources FOR TRADE  # Step 2: Rest of Program expanded_trade_sources <-   sheet_url |>   googlesheets4::read_sheet(sheet = \"Final_Sources_Trade\") |>   expand_trade_sources() ```  Now we build some plots.  Plot showing years covered by `expanded_trade_sources`: ```_{r, fig.alt=\"Plot showing years covered by expanded_trade_sources\"} ggplot2::ggplot(   expanded_trade_sources,   ggplot2::aes(y = Trade, x = Year, fill = \"lightblue\") ) +   ggplot2::geom_tile(alpha = .8) +   ggplot2::theme_dark() +   ggplot2::labs(title = \"Source Availability by Country\") +   ggplot2::scale_fill_identity() +   ggplot2::facet_wrap(~Reporter, ncol = 1) ``` --- title: \"Trade sources year coverage\" output: rmarkdown::html_vignette vignette: >   %\\VignetteIndexEntry{Trade sources year coverage}   %\\VignetteEngine{knitr::rmarkdown}   %\\VignetteEncoding{UTF-8} ---  ```_{r, include = FALSE} knitr::opts_chunk$set(   collapse = TRUE,   comment = \"#>\" ) ``` ```_{r setup} library(WHEP) key_path <- here::here(Sys.getenv(\"GOOGLESHEETS_AUTH_FILE\")) googlesheets4::gs4_auth(path = key_path) ``` pkgdown::build_site() pkgdown::build_articles() rmarkdown::render(\"vignettes/my-vignette.Rmd\", output_format = \"pdf_document\")"},{"path":"https://eduaguilera.github.io/WHEP/articles/workflow-intro.html","id":"environment-variables-and-secrets","dir":"Articles","previous_headings":"R package and renv intro","what":"Environment variables and secrets","title":"Follow the workflow","text":"running code, can sometimes customize behaviour specifying value variable needs. example, maybe option whose value number 1 5, indicating level debugging (amount output want see console, understand code’s execution). possible way introducing known ‘environment variable’, just value stored name ‘environment’ code runs (R variable, related operating system). loaded code starts running, package workflow allows us quite easily, creating top-level file called .Renviron, can include one variable per line, like : can accessed R code using can also use environment variables constants, whatever feel used several places. file uploaded repository, important contain sensitive information (also known ‘secrets’). also introduced section example code Writing articles section, line: example, Excel sheet must read. using googlesheets4 package, can automatically open browser interactively ask Google account credentials, running check tools, want everything work beginning end without human intervention. achievable providing secret token 2. Since must include secret information .Renviron, workaround instead add just secret file path environment variable read , .Renviron uploaded Github secret file, according environment variable found inst/google_cloud_key.json, uploaded. Instead, file uploaded another private storage service, access . examples like one, ideally every developer create use token. specific case token example scope guide, interested probably start gargle package guide. Also, package used easy file path referencing root directory project, paths hard-coded, can read package site.","code":"DEBUG_LEVEL=1 GOOGLESHEETS_AUTH_FILE=inst/google_cloud_key.json Sys.getenv(\"NAME_OF_VARIABLE\") key_path <- here::here(Sys.getenv(\"GOOGLESHEETS_AUTH_FILE\"))"},{"path":"https://eduaguilera.github.io/WHEP/articles/workflow-intro.html","id":"r-code-style-and-formatting","dir":"Articles","previous_headings":"R package and renv intro","what":"R code style and formatting","title":"Follow the workflow","text":"conventions good practices write neat code R. followed style guide Tidyverse style guide. can read just skim get grasp conventions. key can checked automatically. tools conform standards let apply necessary changes code just clicking one button. Analogously, also ways check whether code correctly following style , without explicitly changing . context Tidyverse style guide, two points directly match two R packages: styler: applies Tidyverse style guide specific code, chunk, file entire project. example, apply style whole package simply using command: code editors incorporate way . Since likely using RStudio, can finding styler options ‘addins’ dropdown:  using renv, seems RStudio shows ‘addins’ dropdown options packages included renv, keep mind case want different project, , styler show , means installed current renv environment. important thing keep mind Tidyverse style guide states lines 80 characters, styler package try separate really long single line several lines match 80 character limit. must fix anyway, usual way styler work first manually split code two lines, run styler , can now split rest accordingly. example, : case, use styler may change anything still leave code single line, can help bit sending arguments next line, like : conform standard yet, now trying use styler , able understand going split code accordingly. Depending length line, may leave like (note closing parenthesis goes line): line even longer, split argument line: work now, successfully follow 80 character per line limit. follow limit, fail lintr check (see next point ). lintr: checks whether given code/file/project follows Tidyverse style guide, without making actual changes. responsible making sure check passes (probably using styler explained ), since also automatically checked Pull Requests (see next section guide). check use : default call easy lintr::lint_package(). go detail specific option added , ignore warnings undeclared global variables, false positives using dplyr column names. convenience, following example repository, find call inst/scripts/check_lint.R, want check everything just run script. screenshot can see also options lintr checks Rstudio’s ‘addins’, default perform lintr::lint_package() call without options. Remember added one option check, either find change default behaviour just run script included inst/scripts/check_lint.R. , can see screenshot, things can directly RStudio (like running tests building documentation). guide tried provide code editor agnostic approach everything. Since use RStudio , particularly familiar functionalities, think may helpful , can check .","code":"styler::style_pkg() call_my_incredibly_long_function(my_first_long_argument, my_second_long_argument, my_third_long_argument) call_my_incredibly_long_function(   my_first_long_argument, my_second_long_argument, my_third_long_argument) call_my_incredibly_long_function(   my_first_long_argument, my_second_long_argument, my_third_long_argument ) call_my_incredibly_long_function(   my_first_long_argument,   my_second_long_argument,   my_third_long_argument,   my_fourth_long_argument ) lintr::lint_package(   linters = lintr::linters_with_defaults(object_usage_linter = NULL) )"},{"path":"https://eduaguilera.github.io/WHEP/articles/workflow-intro.html","id":"automatic-checks-on-pull-requests","dir":"Articles","previous_headings":"R package and renv intro","what":"Automatic checks on Pull Requests","title":"Follow the workflow","text":"point assume already done new code, documented tested , perhaps just created report form article. seen Git intro, now time create Pull Request someone else reviews done. create Pull Request, workflow designed two checks run automatically Github, time push changes branch open Pull Request: First, R CMD check performed. seen previous section can run locally, made sure outputs errors. Otherwise, see step failing. , linting check performed. also seen autoformat code, follows R code styling standards, make sure indeed well formatted. Otherwise, see step failing. steps fail, see something like PR page:  Otherwise, checks succeeded, see something like:  Overall, able see bottom PR:  case wondering, checks mentioned actually done single Github automatic step (steps called ‘Github actions’), say ‘1 successful check’ instead ‘2 successful checks’. However, additional Github action , essentially just updates documentation site (PR actually merged main branch). relevant developer makes overall workflow easier, since project documentation automatically updated without human intervention. want know automatic site update can check section R Packages book. Recall PR accepted merged main branch, must also reviewed another developer. good practice make sure Github checks pass even asking someone’s reviewing, check failed likely need add code changes fix , code reviewer checked become obsolete, read , better avoid .","code":""},{"path":"https://eduaguilera.github.io/WHEP/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Catalin Covaci. Author, maintainer. Eduardo Aguilera. Author. João Serra. Contributor.","code":""},{"path":"https://eduaguilera.github.io/WHEP/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Covaci C, Aguilera E (2025). WHEP: Eaten Planet. R package version 0.0.0.9000, https://eduaguilera.github.io/WHEP.","code":"@Manual{,   title = {WHEP: Who Has Eaten the Planet},   author = {Catalin Covaci and Eduardo Aguilera},   year = {2025},   note = {R package version 0.0.0.9000},   url = {https://eduaguilera.github.io/WHEP}, }"},{"path":[]},{"path":[]},{"path":"https://eduaguilera.github.io/WHEP/index.html","id":"who-has-eaten-the-planet-the-paths-of-food-systems-beyond-the-safe-and-just-operating-space-1850-2020","dir":"","previous_headings":"Project","what":"Who Has Eaten the Planet? The paths of food systems beyond the safe and just operating space (1850-2020)","title":"Who Has Eaten the Planet","text":"Food production covers basic human need, simultaneously main driver anthropogenic environmental impacts. impacts resulted transgression, brief period since industrial revolution, planetary boundaries defining safe operating space humanity. rich research literature quantifies last 60 years’ fast, heterogeneous, often unfair development food supply related environmental impacts, depend agro-climatic factors, technology, trade flows, greatly changed different trajectories around world. However, developments lack integrated approach, poorly quantified 1961. WHEP bridge knowledge gaps, assessing “eaten planet” answering questions: environmental impacts food production since 1850? role trade food supply displacing responsibilities impacts? impacts related planetary boundaries, food supply inequality? highly ambitious goals addressed four objectives: Constructing consolidated global country-level annual database agricultural production management, using massive data collation combination modelling. Estimating environmental impacts: greenhouse gas emissions carbon, land, water, nitrogen, phosphorus spatially explicit, integrated, dynamic modelling. Calculating product footprints tracing along international trade chains. Analyzing observed trajectories safe just operating space, assessing drivers, impacts production consumption levels related fair healthy supply. ground-breaking research shed new light environmental history food, opening many new research frontiers, providing necessary information design fair sustainable policies. can also visit European project site.","code":""},{"path":"https://eduaguilera.github.io/WHEP/index.html","id":"r-package","dir":"","previous_headings":"","what":"R package","title":"Who Has Eaten the Planet","text":"WHEP project heavily relies data. use R programming language. repository built R package containing functionality think might useful share others part project. also include functions easily downloading data gathered project.","code":""},{"path":"https://eduaguilera.github.io/WHEP/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Who Has Eaten the Planet","text":"package still early stage thus work progress, ’s still CRAN. can install development version WHEP available GitHub :","code":"pak::pak(\"eduaguilera/WHEP\")"},{"path":"https://eduaguilera.github.io/WHEP/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Who Has Eaten the Planet","text":"can read package’s functionalities documentation reference page.","code":""},{"path":"https://eduaguilera.github.io/WHEP/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Who Has Eaten the Planet","text":"try follow best coding practices, specifically focused R package creation. process roughly summarized : Use git. Work branch. Track dependencies using renv R package. Add new functionality inside R/ directory functions. Add function documentation. Write clean code. Follow Tidyverse style guide. Write tests code. Create pull requests. Ask review. project starting contributors still learning coding best practices. reason created guide explaining things need previous steps, covering git R package development. can find guide . Anyone welcome contribute, highly recommend go guide become familiar workflow still used .","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/WHEP-package.html","id":null,"dir":"Reference","previous_headings":"","what":"WHEP: Who Has Eaten the Planet — WHEP-package","title":"WHEP: Who Has Eaten the Planet — WHEP-package","text":"Gather historical agricultural trade data 1850.","code":""},{"path":[]},{"path":"https://eduaguilera.github.io/WHEP/reference/WHEP-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"WHEP: Who Has Eaten the Planet — WHEP-package","text":"Maintainer: Catalin Covaci catalin.covaci@csic.es (ORCID) Authors: Eduardo Aguilera eduardo.aguilera@csic.es (ORCID) contributors: João Serra jserra@agro.au.dk (ORCID) [contributor]","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/add_area_code.html","id":null,"dir":"Reference","previous_headings":"","what":"Get area codes from area names — add_area_code","title":"Get area codes from area names — add_area_code","text":"Add new column existing tibble corresponding code name. codes assumed defined FABIO model.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/add_area_code.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get area codes from area names — add_area_code","text":"","code":"add_area_code(table, name_column = \"area_name\", code_column = \"area_code\")"},{"path":"https://eduaguilera.github.io/WHEP/reference/add_area_code.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get area codes from area names — add_area_code","text":"table table modified new column. name_column name column table containing names. code_column name output column containing codes.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/add_area_code.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get area codes from area names — add_area_code","text":"tibble contents table extra column named code_column, contains codes. code match, NA included.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/add_area_code.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get area codes from area names — add_area_code","text":"","code":"table <- tibble::tibble(   area_name = c(\"Armenia\", \"Afghanistan\", \"Dummy Country\", \"Albania\") )  add_area_code(table) #> # A tibble: 4 × 2 #>   area_name     area_code #>   <chr>             <dbl> #> 1 Armenia               1 #> 2 Afghanistan           2 #> 3 Dummy Country        NA #> 4 Albania               3  table |>   dplyr::rename(my_area_name = area_name) |>   add_area_code(name_column = \"my_area_name\") #> # A tibble: 4 × 2 #>   my_area_name  area_code #>   <chr>             <dbl> #> 1 Armenia               1 #> 2 Afghanistan           2 #> 3 Dummy Country        NA #> 4 Albania               3  add_area_code(table, code_column = \"my_custom_code\") #> # A tibble: 4 × 2 #>   area_name     my_custom_code #>   <chr>                  <dbl> #> 1 Armenia                    1 #> 2 Afghanistan                2 #> 3 Dummy Country             NA #> 4 Albania                    3"},{"path":"https://eduaguilera.github.io/WHEP/reference/add_area_name.html","id":null,"dir":"Reference","previous_headings":"","what":"Get area names from area codes — add_area_name","title":"Get area names from area codes — add_area_name","text":"Add new column existing tibble corresponding name code. codes assumed defined FABIO model.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/add_area_name.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get area names from area codes — add_area_name","text":"","code":"add_area_name(table, code_column = \"area_code\", name_column = \"area_name\")"},{"path":"https://eduaguilera.github.io/WHEP/reference/add_area_name.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get area names from area codes — add_area_name","text":"table table modified new column. code_column name column table containing codes. name_column name output column containing names.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/add_area_name.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get area names from area codes — add_area_name","text":"tibble contents table extra column named name_column, contains names. name match, NA included.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/add_area_name.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get area names from area codes — add_area_name","text":"","code":"table <- tibble::tibble(area_code = c(1, 2, 4444, 3))  add_area_name(table) #> # A tibble: 4 × 2 #>   area_code area_name   #>       <dbl> <chr>       #> 1         1 Armenia     #> 2         2 Afghanistan #> 3      4444 NA          #> 4         3 Albania      table |>   dplyr::rename(my_area_code = area_code) |>   add_area_name(code_column = \"my_area_code\") #> # A tibble: 4 × 2 #>   my_area_code area_name   #>          <dbl> <chr>       #> 1            1 Armenia     #> 2            2 Afghanistan #> 3         4444 NA          #> 4            3 Albania      add_area_name(table, name_column = \"my_custom_name\") #> # A tibble: 4 × 2 #>   area_code my_custom_name #>       <dbl> <chr>          #> 1         1 Armenia        #> 2         2 Afghanistan    #> 3      4444 NA             #> 4         3 Albania"},{"path":"https://eduaguilera.github.io/WHEP/reference/add_item_code.html","id":null,"dir":"Reference","previous_headings":"","what":"Get item codes from item names — add_item_code","title":"Get item codes from item names — add_item_code","text":"Add new column existing tibble corresponding code item name. codes assumed defined FAOSTAT.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/add_item_code.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get item codes from item names — add_item_code","text":"","code":"add_item_code(table, name_column = \"item_name\", code_column = \"item_code\")"},{"path":"https://eduaguilera.github.io/WHEP/reference/add_item_code.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get item codes from item names — add_item_code","text":"table table modified new column. name_column name column table containing names. code_column name output column containing codes.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/add_item_code.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get item codes from item names — add_item_code","text":"tibble contents table extra column named code_column, contains codes. code match, NA included.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/add_item_code.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get item codes from item names — add_item_code","text":"","code":"table <- tibble::tibble(item_name = c(\"Cottonseed\", \"Eggs\", \"Dummy Item\")) add_item_code(table) #> # A tibble: 3 × 2 #>   item_name  item_code #>   <chr>          <dbl> #> 1 Cottonseed      2559 #> 2 Eggs            2744 #> 3 Dummy Item        NA  table |>   dplyr::rename(my_item_name = item_name) |>   add_item_code(name_column = \"my_item_name\") #> # A tibble: 3 × 2 #>   my_item_name item_code #>   <chr>            <dbl> #> 1 Cottonseed        2559 #> 2 Eggs              2744 #> 3 Dummy Item          NA  add_item_code(table, code_column = \"my_custom_code\") #> # A tibble: 3 × 2 #>   item_name  my_custom_code #>   <chr>               <dbl> #> 1 Cottonseed           2559 #> 2 Eggs                 2744 #> 3 Dummy Item             NA"},{"path":"https://eduaguilera.github.io/WHEP/reference/add_item_name.html","id":null,"dir":"Reference","previous_headings":"","what":"Get item names from item codes — add_item_name","title":"Get item names from item codes — add_item_name","text":"Add new column existing tibble corresponding name item code. codes assumed defined FAOSTAT.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/add_item_name.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get item names from item codes — add_item_name","text":"","code":"add_item_name(table, code_column = \"item_code\", name_column = \"item_name\")"},{"path":"https://eduaguilera.github.io/WHEP/reference/add_item_name.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get item names from item codes — add_item_name","text":"table table modified new column. code_column name column table containing codes. name_column name output column containing names.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/add_item_name.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get item names from item codes — add_item_name","text":"tibble contents table extra column named name_column, contains names. name match, NA included.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/add_item_name.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get item names from item codes — add_item_name","text":"","code":"table <- tibble::tibble(item_code = c(2559, 2744, 9876)) add_item_name(table) #> # A tibble: 3 × 2 #>   item_code item_name  #>       <dbl> <chr>      #> 1      2559 Cottonseed #> 2      2744 Eggs       #> 3      9876 NA          table |>   dplyr::rename(my_item_code = item_code) |>   add_item_name(code_column = \"my_item_code\") #> # A tibble: 3 × 2 #>   my_item_code item_name  #>          <dbl> <chr>      #> 1         2559 Cottonseed #> 2         2744 Eggs       #> 3         9876 NA          add_item_name(table, name_column = \"my_custom_name\") #> # A tibble: 3 × 2 #>   item_code my_custom_name #>       <dbl> <chr>          #> 1      2559 Cottonseed     #> 2      2744 Eggs           #> 3      9876 NA"},{"path":"https://eduaguilera.github.io/WHEP/reference/add_process_code.html","id":null,"dir":"Reference","previous_headings":"","what":"Get process codes from process names — add_process_code","title":"Get process codes from process names — add_process_code","text":"Add new column existing tibble corresponding code process name. codes assumed defined FABIO model.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/add_process_code.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get process codes from process names — add_process_code","text":"","code":"add_process_code(   table,   name_column = \"process_name\",   code_column = \"process_code\" )"},{"path":"https://eduaguilera.github.io/WHEP/reference/add_process_code.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get process codes from process names — add_process_code","text":"table table modified new column. name_column name column table containing names. code_column name output column containing codes.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/add_process_code.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get process codes from process names — add_process_code","text":"tibble contents table extra column named code_column, contains codes. code match, NA included.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/add_process_code.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get process codes from process names — add_process_code","text":"","code":"table <- tibble::tibble(   process_name = c(\"Beans production\", \"Olive Oil extraction\", \"Dummy\") ) add_process_code(table) #> # A tibble: 3 × 2 #>   process_name         process_code #>   <chr>                <chr>        #> 1 Beans production     p017         #> 2 Olive Oil extraction p076         #> 3 Dummy                NA            table |>   dplyr::rename(my_process_name = process_name) |>   add_process_code(name_column = \"my_process_name\") #> # A tibble: 3 × 2 #>   my_process_name      process_code #>   <chr>                <chr>        #> 1 Beans production     p017         #> 2 Olive Oil extraction p076         #> 3 Dummy                NA            add_process_code(table, code_column = \"my_custom_code\") #> # A tibble: 3 × 2 #>   process_name         my_custom_code #>   <chr>                <chr>          #> 1 Beans production     p017           #> 2 Olive Oil extraction p076           #> 3 Dummy                NA"},{"path":"https://eduaguilera.github.io/WHEP/reference/add_process_name.html","id":null,"dir":"Reference","previous_headings":"","what":"Get process names from process codes — add_process_name","title":"Get process names from process codes — add_process_name","text":"Add new column existing tibble corresponding name process code. codes assumed defined FABIO model.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/add_process_name.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get process names from process codes — add_process_name","text":"","code":"add_process_name(   table,   code_column = \"process_code\",   name_column = \"process_name\" )"},{"path":"https://eduaguilera.github.io/WHEP/reference/add_process_name.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get process names from process codes — add_process_name","text":"table table modified new column. code_column name column table containing codes. name_column name output column containing names.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/add_process_name.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get process names from process codes — add_process_name","text":"tibble contents table extra column named name_column, contains names. name match, NA included.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/add_process_name.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get process names from process codes — add_process_name","text":"","code":"table <- tibble::tibble(process_code = c(\"p017\", \"p076\", \"dummy\")) add_process_name(table) #> # A tibble: 3 × 2 #>   process_code process_name         #>   <chr>        <chr>                #> 1 p017         Beans production     #> 2 p076         Olive Oil extraction #> 3 dummy        NA                    table |>   dplyr::rename(my_process_code = process_code) |>   add_process_name(code_column = \"my_process_code\") #> # A tibble: 3 × 2 #>   my_process_code process_name         #>   <chr>           <chr>                #> 1 p017            Beans production     #> 2 p076            Olive Oil extraction #> 3 dummy           NA                    add_process_name(table, name_column = \"my_custom_name\") #> # A tibble: 3 × 2 #>   process_code my_custom_name       #>   <chr>        <chr>                #> 1 p017         Beans production     #> 2 p076         Olive Oil extraction #> 3 dummy        NA"},{"path":"https://eduaguilera.github.io/WHEP/reference/build_supply_use.html","id":null,"dir":"Reference","previous_headings":"","what":"Supply and use tables — build_supply_use","title":"Supply and use tables — build_supply_use","text":"Create table processes, inputs (use) outputs (supply).","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/build_supply_use.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Supply and use tables — build_supply_use","text":"","code":"build_supply_use()"},{"path":"https://eduaguilera.github.io/WHEP/reference/build_supply_use.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Supply and use tables — build_supply_use","text":"tibble supply use data processes. contains following columns: year: year recorded event occurred. area: name country data . proc: Natural language name process taking place. item: Natural language name item taking part process. type: Can two values: use: given item input process. supply: given item output process. value: Quantity tonnes.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/build_supply_use.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Supply and use tables — build_supply_use","text":"","code":"if (FALSE) { # \\dontrun{ build_supply_use() } # }"},{"path":"https://eduaguilera.github.io/WHEP/reference/expand_trade_sources.html","id":null,"dir":"Reference","previous_headings":"","what":"Trade data sources — expand_trade_sources","title":"Trade data sources — expand_trade_sources","text":"Create new dataframe row year range one row single year, effectively 'expanding' whole year range.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/expand_trade_sources.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Trade data sources — expand_trade_sources","text":"","code":"expand_trade_sources(trade_sources)"},{"path":"https://eduaguilera.github.io/WHEP/reference/expand_trade_sources.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Trade data sources — expand_trade_sources","text":"trade_sources tibble dataframe row contains year range.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/expand_trade_sources.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Trade data sources — expand_trade_sources","text":"tibble dataframe row corresponds single year given source.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/expand_trade_sources.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Trade data sources — expand_trade_sources","text":"","code":"trade_sources <- tibble::tibble(   Name = c(\"a\", \"b\", \"c\"),   Trade = c(\"t1\", \"t2\", \"t3\"),   Info_Format = c(\"year\", \"partial_series\", \"year\"),   Timeline_Start = c(1, 1, 2),   Timeline_End = c(3, 4, 5),   Timeline_Freq = c(1, 1, 2),   `Imp/Exp` = \"Imp\",   SACO_link = NA, ) expand_trade_sources(trade_sources) #> # A tibble: 9 × 12 #> # Groups:   No [3] #>      No  Year Name  Trade Info_Format  Timeline_Start Timeline_End Timeline_Freq #>   <int> <dbl> <chr> <chr> <chr>                 <dbl>        <dbl>         <dbl> #> 1     1     1 a_1   t1    year                      1            3             1 #> 2     1     2 a_2   t1    year                      1            3             1 #> 3     1     3 a_3   t1    year                      1            3             1 #> 4     2     1 b     t2    partial_ser…              1            4             1 #> 5     2     2 b     t2    partial_ser…              1            4             1 #> 6     2     3 b     t2    partial_ser…              1            4             1 #> 7     2     4 b     t2    partial_ser…              1            4             1 #> 8     3     2 c_2   t3    year                      2            5             2 #> 9     3     4 c_4   t3    year                      2            5             2 #> # ℹ 4 more variables: `Imp/Exp` <chr>, SACO_link <lgl>, ImpExp <chr>, #> #   In_Saco <int>"},{"path":"https://eduaguilera.github.io/WHEP/reference/get_bilateral_trade.html","id":null,"dir":"Reference","previous_headings":"","what":"Bilateral trade data — get_bilateral_trade","title":"Bilateral trade data — get_bilateral_trade","text":"Clean CSV data given file_path. Fill missing data balance trade totals.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/get_bilateral_trade.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bilateral trade data — get_bilateral_trade","text":"","code":"get_bilateral_trade(file_path)"},{"path":"https://eduaguilera.github.io/WHEP/reference/get_bilateral_trade.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bilateral trade data — get_bilateral_trade","text":"file_path local path input CSV located. recommended use autogenerated path get_file_path() function.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/get_bilateral_trade.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bilateral trade data — get_bilateral_trade","text":"tibble reported trade countries. efficient memory usage, tibble exactly tidy format. contains following columns: year: year recorded event occurred. item: Natural language name item traded. bilateral_trade: Square matrix NxN dimensions N total number countries considered. matrix row column names exactly equal represent country codes. Row name: FAOSTAT internal code country exporting item. Equivalences ISO 3166-1 numeric can found Area Codes CSV zip file can downloaded FAOSTAT. TODO: Think , nice use ISO3 codes enough periods Column name: FAOSTAT internal code country importing item. See row name explanation . m matrix, value m[\"\", \"B\"] trade tonnes country \"\" country \"B\", corresponding year item. matrix can considered balanced. means: sum values row \"\", \"\" country, match total exports country \"\" reported commodity balance sheet (considered accurate totals). sum values column \"\", \"\" country, match total imports country \"\" reported commodity balance sheet (considered accurate totals). sums may exactly expected values precision issues /iterative proportional fitting algorithm converging fast enough, relatively close desired totals. step step approach obtain data tries follow FABIO model explained . steps performed separately group year item. FAOSTAT reported bilateral trade, sometimes two values one trade flow: exported amount claimed reporter country import amount claimed partner country. , export data preferred, .e., country \"\" says exported X tonnes country \"B\" country \"B\" claims got Y tonnes country \"\", trust export data X. choice needed exists reported amount sides. Otherwise, single existing report chosen. Complete country data, , add missing combinations country trade NAs, estimated later. matrix form, increase memory usage since build matrix anyway (balancing algorithm), empty parts also take memory. also done total imports/exports commodity balance sheet, directly filled 0s instead. total imports exports commodity balance sheet balanced downscaling largest two match lowest. done following way: total_imports > total_exports: Set import total_exports * import / total_import. total_exports > total_exports: Set export total_exports * export / total_export. missing data matrix must estimated. done like : pair exporter importer j, estimate bilateral trade m[, j] using export shares import shares j commodity balance sheet: est_1 <- exports[] * imports[j] / sum(imports), .e., total exports country spread among countries' import shares. est_2 <- imports[j] * exports[] / sum(exports), .e. total imports country j spread among countries' export shares. est <- (est_1 + est_2) / 2, .e., mean estimates. computations, exports imports original values balanced. estimates data already existed (.e. non-NA) discarded. ones left, row (.e. exporter country), get difference balanced total export sum original non-estimated data. result gap can actually fill estimates, get past reported total export. sum non-discarded estimates larger, must downscaled spread computing gap * non_discarded_estimate / sum(non_discarded_estimates). estimates divided trust factor, sense rely whole value, thinking non-present value might actually specific trade 0, overestimate much. chosen factor 10%, 10% estimate's value actually used fill NA original bilateral trade matrix. matrix balanced, mentioned , using iterative proportional fitting algorithm. target sums rows columns respectively balanced exports imports computed commodity balance sheet. algorithm performed directly using mipfp R package.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/get_bilateral_trade.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bilateral trade data — get_bilateral_trade","text":"","code":"if (FALSE) { # \\dontrun{ get_bilateral_trade(get_file_path(\"bilateral_trade\")) } # }"},{"path":"https://eduaguilera.github.io/WHEP/reference/get_faostat_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Scrapes activity_data from FAOSTAT and slightly post-processes it — get_faostat_data","title":"Scrapes activity_data from FAOSTAT and slightly post-processes it — get_faostat_data","text":"Important: Dynamically allows introduction subsets \"...\". Note: overhead individually scraping FAOSTAT code QCL crop data; fine.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/get_faostat_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scrapes activity_data from FAOSTAT and slightly post-processes it — get_faostat_data","text":"","code":"get_faostat_data(activity_data, ...)"},{"path":"https://eduaguilera.github.io/WHEP/reference/get_faostat_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scrapes activity_data from FAOSTAT and slightly post-processes it — get_faostat_data","text":"activity_data activity data required FAOSTAT; needs one c('livestock','crop_area','crop_yield','crop_production'). ... can whichever column name get_faostat_bulk, particularly year, area ISO3_CODE.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/get_faostat_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scrapes activity_data from FAOSTAT and slightly post-processes it — get_faostat_data","text":"data.frame FAOSTAT activity_data; default years countries.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/get_faostat_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scrapes activity_data from FAOSTAT and slightly post-processes it — get_faostat_data","text":"","code":"if (FALSE) { # \\dontrun{ get_faostat_data(\"livestock\") get_faostat_data(\"livestock\", year = 2010, area = \"Portugal\") } # }"},{"path":"https://eduaguilera.github.io/WHEP/reference/get_file_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Download and cache files — get_file_path","title":"Download and cache files — get_file_path","text":"requested file exist locally, downloaded public link stored cache directory obtained using tools::R_user_dir.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/get_file_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download and cache files — get_file_path","text":"","code":"get_file_path(file_alias, force_download = FALSE)"},{"path":"https://eduaguilera.github.io/WHEP/reference/get_file_path.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download and cache files — get_file_path","text":"file_alias Alias requested file. now possible values : \"commodity_balance_sheet\": Intended get_wide_cbs(). \"bilateral_trade\": Intended get_bilateral_trade(). \"processing_coefs\": Intended get_processing_coefs(). force_download TRUE, try cache file redownloads anyway.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/get_file_path.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download and cache files — get_file_path","text":"character vector path requested file located","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/get_file_path.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download and cache files — get_file_path","text":"","code":"if (FALSE) { # \\dontrun{ get_file_path(\"processing_coefs\") get_file_path(\"commodity_balance_sheet\", force_download = TRUE) } # }"},{"path":"https://eduaguilera.github.io/WHEP/reference/get_processing_coefs.html","id":null,"dir":"Reference","previous_headings":"","what":"Processed products share factors — get_processing_coefs","title":"Processed products share factors — get_processing_coefs","text":"Clean CSV data given file_path.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/get_processing_coefs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Processed products share factors — get_processing_coefs","text":"","code":"get_processing_coefs(file_path)"},{"path":"https://eduaguilera.github.io/WHEP/reference/get_processing_coefs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Processed products share factors — get_processing_coefs","text":"file_path local path input CSV located. recommended use autogenerated path get_file_path() function.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/get_processing_coefs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Processed products share factors — get_processing_coefs","text":"tibble quantities processed product. contains following columns: year: year recorded event occurred. area: name country data . area_code: FAOSTAT internal code country. Equivalences ISO 3166-1 numeric can found Area Codes CSV zip file can downloaded FAOSTAT. TODO: Think , nice use ISO3 codes enough periods item_to_process: Natural language name item processed give subproduct items. item_to_process_code: FAOSTAT internal code items. value_to_process: tonnes item processed. matches amount found processing column data obtained get_wide_cbs(). item_processed: Natural language name subproduct item obtained. initial_conversion_factor: estimate number tonnes item_processed obtained tonne item_to_process. used compute final_conversion_factor, leaves everything balanced. TODO: explain computed. initial_value_processed: first estimate number tonnes item_processed obtained item_to_process. computed value_to_process * initial_conversion_factor. conversion_factor_scaling: computed scaling needed adapt initial_conversion_factor get final balanced total subproduct quantities. TODO: explain computed. final_conversion_factor: final used estimate number tonnes item_processed obtained tonne item_to_process. computed initial_conversion_factor * conversion_factor_scaling. final_value_processed: final estimate number tonnes item_processed obtained item_to_process. computed initial_value_processed * final_conversion_factor. final data obtained, quantities final_value_processed balanced following sense: total sum final_value_processed unique tuple (year, area_code, item_processed) exactly quantity reported year, country item_processed item production column obtained get_wide_cbs(). primary products, amount 'production' actually amount subproduct obtained. TODO: Fix data hold.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/get_processing_coefs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Processed products share factors — get_processing_coefs","text":"","code":"if (FALSE) { # \\dontrun{ get_processing_coefs(get_file_path(\"processing_coefs\")) } # }"},{"path":"https://eduaguilera.github.io/WHEP/reference/get_wide_cbs.html","id":null,"dir":"Reference","previous_headings":"","what":"Commodity balance sheet data — get_wide_cbs","title":"Commodity balance sheet data — get_wide_cbs","text":"Clean CSV data given file_path.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/get_wide_cbs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Commodity balance sheet data — get_wide_cbs","text":"","code":"get_wide_cbs(file_path)"},{"path":"https://eduaguilera.github.io/WHEP/reference/get_wide_cbs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Commodity balance sheet data — get_wide_cbs","text":"file_path local path input CSV located. recommended use autogenerated path get_file_path() function.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/get_wide_cbs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Commodity balance sheet data — get_wide_cbs","text":"tibble commodity balance sheet data wide format. contains following columns: year: year recorded event occurred. area: name country data . area_code: FAOSTAT internal code country. Equivalences ISO 3166-1 numeric can found Area Codes CSV zip file can downloaded FAOSTAT. TODO: Think , nice use ISO3 codes enough periods item: Natural language name item. item_code: FAOSTAT internal code item. columns quantities (measured tonnes), total supply total use balanced. supply: production: Produced locally. import: Obtained importing countries. stock_retrieval: Available net stock previous years. ease, one stock column included supply. value positive, stock quantity available supply. Otherwise, means larger quantity stored later years used supply, deduce total supply. Since case negative, total supply still computed sum . use: food: Food humans. feed: Food animals. export: Released export countries. seed: Intended new production. processing: product used obtain subproducts. other_uses: use included ones. additional column domestic_supply computed total use excluding export.","code":""},{"path":"https://eduaguilera.github.io/WHEP/reference/get_wide_cbs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Commodity balance sheet data — get_wide_cbs","text":"","code":"if (FALSE) { # \\dontrun{ get_wide_cbs(get_file_path(\"commodity_balance_sheet\")) } # }"}]
