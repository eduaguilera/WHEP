#' Commodity balance sheet data
#'
#' @description
#' Clean CSV data from the given `file_path`. It is recommended to use an
#' autogenerated path by `get_file_path()` function.
#'
#' @param file_path The local path where the input CSV is located
#'
#' @returns
#' A tibble with the commodity balance sheet data in wide format.
#' It contains the following columns:
#' - `year`: The year when the data was collected.
#' - `area`: The name of the country where the data is from.
#' - `area_code`: FAOSTAT internal code for each country. Equivalences
#'    with ISO 3166-1 numeric can be found in the _Area Codes_ CSV from the
#'    zip file that can be downloaded from
#'    [FAOSTAT](https://www.fao.org/faostat/en/#data/FBS). TODO: Think about
#'    this, would be nice to use ISO3 codes but won't be enough for our periods
#' - `item`: Natural language name for the item.
#' - `item_code`: FAOSTAT internal code for each item.
#'
#' The other columns are quantities (measured in tonnes), where total supply
#' and total use should be balanced.
#'
#' For supply:
#'    - `production`: Produced locally.
#'    - `import`: Obtained from importing from other countries.
#'    - `stock_retrieval`: Available as net stock from previous years. For ease,
#'      only one stock column is included here as supply. If the value is
#'      positive, there is a stock quantity available as supply. Otherwise, it
#'      means a larger quantity was stored for later years and cannot be used as
#'      supply, having to deduce it from total supply. Since in this case it is
#'      negative, the total supply is still computed as the sum of all of these.
#'
#' For use:
#'    - `food`: Food for humans.
#'    - `feed`: Food for animals.
#'    - `export`: Released as export for other countries.
#'    - `seed`: Intended for new production.
#'    - `processing`: The product will be used to obtain other subproducts.
#'    - `other_uses`: Any other use not included in the above ones.
#'
#' There is an additional column `domestic_supply` which is computed as the
#' total use excluding `export`.
#'
#' @export
#'
#' @examples
#' \dontrun{
#' get_wide_cbs(get_file_path("commodity_balance_sheet"))
#' }
get_wide_cbs <- function(file_path) {
  file_path |>
    readr::read_csv(show_col_types = FALSE) |>
    tidyr::pivot_wider(names_from = Element, values_from = Value) |>
    dplyr::rename_with(tolower) |>
    dplyr::mutate(stock_retrieval = -stock_variation, .keep = "unused")
}

#' Processed products share factors
#'
#' @description
#' Clean CSV data from the given `file_path`. It is recommended to use an
#' autogenerated path by `get_file_path()` function.
#'
#' @param file_path The local path where the input CSV is located
#'
#' @returns
#' A tibble with the quantities for each processed product.
#' It contains the following columns:
#' - `year`: The year when the data was collected.
#' - `area`: The name of the country where the data is from.
#' - `area_code`: FAOSTAT internal code for each country. Equivalences
#'    with ISO 3166-1 numeric can be found in the _Area Codes_ CSV from the
#'    zip file that can be downloaded from
#'    [FAOSTAT](https://www.fao.org/faostat/en/#data/FBS). TODO: Think about
#'    this, would be nice to use ISO3 codes but won't be enough for our periods
#' - `item_to_process`: Natural language name for the item that is being
#'    processed and will give other subproduct items.
#' - `item_to_process_code`: FAOSTAT internal code for each of those items.
#' - `value_to_process`: tonnes of this item that are being processed. It
#'    matches the amount found in the `processing` column from the data
#'    obtained by `get_wide_cbs()`.
#' - `item_processed`: Natural language name for the subproduct item obtained.
#' - `initial_conversion_factor`: estimate for the number of tonnes of
#'    `item_processed` obtained for each tonne of `item_to_process`. It will be
#'    used to compute the `final_conversion_factor`, which leaves everything
#'    balanced. TODO: explain how it's computed.
#' - `initial_value_processed`: first estimate for the number of tonnes of
#'    `item_processed` obtained from `item_to_process`. It is computed as
#'    `value_to_process * initial_conversion_factor`.
#' - `conversion_factor_scaling`: computed scaling needed to adapt
#'    `initial_conversion_factor` so as to get a final balanced total of
#'    subproduct quantities. TODO: explain how it's computed.
#' - `final_conversion_factor`: final used estimate for the number of tonnes of
#'    `item_processed` obtained for each tonne of `item_to_process`. It is
#'    computed as `initial_conversion_factor * conversion_factor_scaling`.
#' - `final_value_processed`: final estimate for the number of tonnes of
#'    `item_processed` obtained from `item_to_process`. It is computed as
#'    `initial_value_processed * final_conversion_factor`.
#'
#' For the final data obtained, the quantities `final_value_processed` are
#' balanced in the following sense: the total sum of `final_value_processed`
#' for each unique tuple of `(year, area_code, item_processed)` should be
#' exactly the quantity reported for that year, country and `item_processed`
#' item in the `production` column obtained from `get_wide_cbs()`. This is
#' because they are not primary products, so the amount from 'production' is
#' actually the amount of subproduct obtained. TODO: Fix few data where this
#' doesn't hold.
#'
#' @export
#'
#' @examples
#' \dontrun{
#' get_processing_coefs(get_file_path("processing_coefs"))
#' }
get_processing_coefs <- function(file_path) {
  file_path |>
    readr::read_csv(show_col_types = FALSE) |>
    dplyr::select(-Item, -Element) |>
    dplyr::rename_with(tolower) |>
    dplyr::rename(
      item_to_process = processeditem,
      item_to_process_code = item_code,
      value_to_process = value,
      item_processed = item,
      initial_conversion_factor = product_fraction,
      initial_value_processed = value_proc_raw,
      conversion_factor_scaling = scaling,
      final_conversion_factor = cf,
      final_value_processed = value_proc
    )
}
